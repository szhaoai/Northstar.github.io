export const siteData = {
  "lastUpdated": "2025-12-27T00:23:00Z",
  "news": [
    {
      "id": "n0",
      "title": "The Meteoric Rise of Manus AI: A Deep Analysis of Success, Strategy, and Challenges",
      "summary": "Manus AI achieved what industry observers are calling the fastest revenue ramp in startup history—reaching $100 million in annual recurring revenue within eight months of launch, culminating in a $2+ billion acquisition by Meta in December 2025. This analysis examines the multifaceted factors behind this unprecedented trajectory: visionary leadership, impeccable market timing, technical differentiation, aggressive growth tactics, and fortuitous circumstances, alongside the substantial challenges that complicated its path.",
      "source": "Local ML Monitor",      
      "date": "2025-12-26",
      "category": "M&A"
    }
  

    
    {
      "id": "n1",
      "title": "Scaling Laws Still Intact: New Research Findings",
      "summary": "Recent compute-optimal scaling analysis confirms that we are still far from hitting data ceilings for large model pre-training.",
      "source": "Local ML Monitor",
      "url": "https://arxiv.org",
      "date": "2025-12-26",
      "category": "LLM"
    }


    
    {
      "id": "n2",
      "title": "Open-Source Agents Outperform Proprietary Baselines",
      "summary": "A breakthrough in small model reasoning allows 7B parameters agents to handle complex multi-step workflows previously reserved for GPT-4.",
      "source": "Local ML Monitor",
      "url": "https://huggingface.co",
      "date": "2025-12-26",
      "category": "Agents"
    }
  ],
  "projects": [
    {
      "id": "p1",
      "name": "Local News Curator",
      "description": "A Python-based agent that monitors 50+ AI sources and generates this website's content daily.",
      "tech": ["Python", "NVIDIA GPU", "React"],
      "image": "https://picsum.photos/seed/curator/800/400"
    }
  ],
  "blogPosts": [
    {
      "id": "b2",
      "title": "Trump's New AI Order, Big Tech's Model Arms Race, and What It Means for 2026",
      "excerpt": "This week in AI saw a major U.S. executive order to centralize AI regulation, new multimodal model releases from OpenAI and Google, and continued investment in edge and enterprise AI. Together, they signal a shift toward heavily regulated but deeply embedded AI across government, industry, and everyday devices.",
      "content": "Over the last week, artificial intelligence news has been dominated by two intertwined forces: aggressive government intervention and an escalating race among major labs to ship ever more capable multimodal models. The result is a landscape where AI is no longer an experimental add‑on but a core layer of policy, infrastructure, and consumer technology.\n\nIn Washington, President Donald Trump signed a sweeping executive order on December 11 titled \"Ensuring a National Policy Framework for Artificial Intelligence.\" The order directs federal agencies to challenge state‑level AI rules deemed overly restrictive, tying some federal funding to states' willingness to align with a national standard. Supporters frame this as a necessary move to prevent a patchwork of fifty incompatible AI laws; critics warn it could undercut local protections on issues like algorithmic bias, data privacy, and deepfake harms. Either way, the U.S. has taken a clear step toward centralized AI governance.\n\nWhile policymakers argue over the rules, AI labs are racing ahead. OpenAI has continued iterating beyond GPT‑5, rolling out updated GPT‑4.5‑class and GPT‑5‑series models that emphasize reasoning, tools, and multimodal understanding across text, images, audio, and video. Google, meanwhile, introduced Gemini 3 Flash and expanded the Gemma and Gemma‑on‑edge lines, designed to run surprisingly capable small language models directly on constrained devices with as little as 2 GB of RAM. This shift to \"good enough\" on‑device intelligence suggests that, in 2026, many AI experiences will feel local and instant rather than cloud‑bound and laggy.\n\nEnterprise and infrastructure stories rounded out the week. NIST announced new investment in AI centers dedicated to manufacturing and critical‑infrastructure cybersecurity, underscoring how AI is moving from pilot projects to core operational tooling. Cloud providers are leaning into hybrid AI, letting banks, manufacturers, and governments combine sensitive on‑premise data with cloud‑hosted models for training and simulation. At the same time, regulators in the U.S. and Europe are probing competition, content safety, and abuse risks, from antitrust concerns around foundation models to proposed bans on \"nudification\" tools that generate abusive imagery.\n\nTaken together, last week's developments make one thing clear: AI is entering a normalization phase. Instead of asking whether AI will be adopted, policymakers and builders are now negotiating who writes the rules, where the models run, and how the benefits and harms are distributed. For anyone working in technology, law, or education, 2026 is shaping up not as the start of the AI era—but as the year when AI becomes the baseline expectation.",
      "date": "2025-12-26",
      "category": "Technology",
      "readTime": "4 min"
    },
    {
      "id": "b1",
      "title": "The GPU Standard: Why Compute is the New Oil",
      "excerpt": "Analyzing the shift from monetary liquidity to compute liquidity as the primary driver of technological growth.",
      "content": "...",
      "date": "2025-12-26",
      "category": "Economics",
      "readTime": "12 min"
    }
  ],
  "chineseWritings": [
    {
      "id": "w1",
      "title": "桃李春风一杯酒，江湖夜雨十年灯。",
      "originalTitle": "渥村往事",
      "date": "2025-12-26",
      "tags": ["哲学", "随笔"],
      "content": "..."
    }
  ]
};
